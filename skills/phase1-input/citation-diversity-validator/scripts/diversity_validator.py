"""
å¼•ç”¨å¤šæ ·æ€§éªŒè¯å™¨
éªŒè¯è®ºæ–‡å¼•ç”¨æ˜¯å¦æ»¡è¶³ç¾èµ›Oå¥–çº§åˆ«çš„å¤šæ ·æ€§è¦æ±‚
"""

import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import yaml

logger = logging.getLogger(__name__)


@dataclass
class ValidationConfig:
    """éªŒè¯é…ç½®"""
    min_total_citations: int = 8
    max_total_citations: int = 15
    min_categories: int = 4
    min_diversity_score: float = 0.75
    strict_mode: bool = True
    
    category_requirements: Dict[str, Dict] = field(default_factory=lambda: {
        'academic_papers': {'min': 3, 'weight': 0.40, 'required': False},
        'government_reports': {'min': 1, 'weight': 0.15, 'required': False},
        'official_data': {'min': 1, 'weight': 0.15, 'required': False},
        'problem_references': {'min': 1, 'weight': 0.15, 'required': True},
        'other_sources': {'min': 0, 'weight': 0.15, 'required': False}
    })


class CitationDiversityValidator:
    """å¼•ç”¨å¤šæ ·æ€§éªŒè¯å™¨"""
    
    # ç±»åˆ«æ ‡ç­¾æ˜ å°„
    CATEGORY_MAPPING = {
        'academic': 'academic_papers',
        'journal': 'academic_papers',
        'conference': 'academic_papers',
        'preprint': 'academic_papers',
        'arxiv': 'academic_papers',
        'government': 'government_reports',
        'report': 'government_reports',
        'techreport': 'government_reports',
        'whitepaper': 'government_reports',
        'data': 'official_data',
        'dataset': 'official_data',
        'database': 'official_data',
        'problem': 'problem_references',
        'mcm': 'problem_references',
        'icm': 'problem_references',
        'comap': 'problem_references',
        'media': 'other_sources',
        'news': 'other_sources',
        'technical': 'other_sources',
        'documentation': 'other_sources',
        'github': 'other_sources',
        'web': 'other_sources',
        'other': 'other_sources'
    }
    
    # æœç´¢å»ºè®®
    SEARCH_SUGGESTIONS = {
        'academic_papers': [
            "[ä¸»é¢˜] peer-reviewed journal article",
            "[ä¸»é¢˜] systematic review meta-analysis",
            "[ä¸»é¢˜] mathematical modeling optimization study",
            "[ä¸»é¢˜] recent research advances 2024 2025"
        ],
        'government_reports': [
            "[ä¸»é¢˜] government report official statistics",
            "[ä¸»é¢˜] World Bank publication report",
            "[ä¸»é¢˜] UN United Nations report",
            "[ä¸»é¢˜] OECD policy analysis",
            "[ä¸»é¢˜] EPA CDC DOE official report"
        ],
        'official_data': [
            "ç¡®ä¿data-collectorå·²ä¸ºè·å–çš„æ•°æ®ç”Ÿæˆå¼•ç”¨",
            "[ä¸»é¢˜] World Bank open data indicator",
            "[ä¸»é¢˜] UN statistics database",
            "[ä¸»é¢˜] official government statistics data"
        ],
        'problem_references': [
            "å¿…é¡»å¼•ç”¨MCM/ICMå®˜æ–¹é¢˜ç›®å£°æ˜",
            "å¦‚æœ‰æ•°æ®æ–‡ä»¶ï¼Œéœ€å¼•ç”¨å®˜æ–¹æä¾›çš„æ•°æ®é›†",
            "ä½¿ç”¨problem-reference-extractoræå–é¢˜ç›®å¼•ç”¨"
        ],
        'other_sources': [
            "[ä¸»é¢˜] industry report white paper",
            "[ä¸»é¢˜] technical documentation standard",
            "GitHub repository for methodology implementation"
        ]
    }
    
    def __init__(self, config: Optional[ValidationConfig] = None, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            config: éªŒè¯é…ç½®å¯¹è±¡
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        if config:
            self.config = config
        elif config_path:
            self.config = self._load_config(config_path)
        else:
            self.config = ValidationConfig()
    
    def _load_config(self, config_path: str) -> ValidationConfig:
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
            
            if data is None:
                logger.warning(f"Config file {config_path} is empty, using defaults")
                return ValidationConfig()
            
            return ValidationConfig(
                min_total_citations=data.get('validation_rules', {}).get('min_total_citations', 8),
                max_total_citations=data.get('validation_rules', {}).get('max_total_citations', 15),
                min_categories=data.get('validation_rules', {}).get('min_categories', 4),
                min_diversity_score=data.get('validation_rules', {}).get('min_diversity_score', 0.75),
                strict_mode=data.get('strict_mode', True),
                category_requirements=data.get('category_requirements', ValidationConfig().category_requirements)
            )
        except FileNotFoundError:
            logger.warning(f"Config file not found: {config_path}, using defaults")
            return ValidationConfig()
        except yaml.YAMLError as e:
            logger.warning(f"Invalid YAML in config file {config_path}: {e}, using defaults")
            return ValidationConfig()
        except (IOError, OSError) as e:
            logger.warning(f"Failed to read config file {config_path}: {e}, using defaults")
            return ValidationConfig()
        except Exception as e:
            logger.warning(f"Unexpected error loading config from {config_path}: {e}, using defaults")
            return ValidationConfig()
    
    def validate(self, citations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        éªŒè¯å¼•ç”¨å¤šæ ·æ€§
        
        Args:
            citations: å¼•ç”¨åˆ—è¡¨ï¼Œæ¯ä¸ªå¼•ç”¨éœ€åŒ…å«bibtex_keyå’Œcategoryå­—æ®µ
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        # 1. åˆ†ç±»ç»Ÿè®¡
        categorized = self._categorize_citations(citations)
        
        # 2. è®¡ç®—å„ç±»åˆ«ç»Ÿè®¡
        category_details = self._calculate_category_details(categorized)
        
        # 3. è®¡ç®—å¤šæ ·æ€§è¯„åˆ†
        diversity_score = self._calculate_diversity_score(category_details)
        
        # 4. æ£€æŸ¥æ˜¯å¦é€šè¿‡
        validation_result = self._check_validation(citations, category_details, diversity_score)
        
        # 5. ç”Ÿæˆå»ºè®®å’Œè­¦å‘Š
        recommendations, warnings = self._generate_recommendations(
            citations, category_details, diversity_score
        )
        
        return {
            'validation_result': validation_result,
            'category_details': category_details,
            'recommendations': recommendations,
            'warnings': warnings
        }
    
    def _categorize_citations(self, citations: List[Dict]) -> Dict[str, List[Dict]]:
        """å°†å¼•ç”¨æŒ‰ç±»åˆ«åˆ†ç»„"""
        categorized = {
            'academic_papers': [],
            'government_reports': [],
            'official_data': [],
            'problem_references': [],
            'other_sources': []
        }
        
        for citation in citations:
            category_raw = citation.get('category', 'other').lower()
            category = self.CATEGORY_MAPPING.get(category_raw, 'other_sources')
            categorized[category].append(citation)
        
        return categorized
    
    def _calculate_category_details(
        self,
        categorized: Dict[str, List[Dict]]
    ) -> Dict[str, Dict[str, Any]]:
        """è®¡ç®—æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†ä¿¡æ¯"""
        details = {}
        
        for category, citations in categorized.items():
            req = self.config.category_requirements.get(category, {'min': 0, 'weight': 0})
            count = len(citations)
            required = req.get('min', 0)
            
            details[category] = {
                'count': count,
                'required': required,
                'status': 'pass' if count >= required else 'fail',
                'citations': [c.get('bibtex_key', 'unknown') for c in citations],
                'weight': req.get('weight', 0),
                'is_required': req.get('required', False)
            }
        
        return details
    
    def _calculate_diversity_score(self, category_details: Dict[str, Dict]) -> float:
        """è®¡ç®—å¤šæ ·æ€§è¯„åˆ†"""
        score = 0.0
        
        for category, details in category_details.items():
            weight = details.get('weight', 0)
            count = details.get('count', 0)
            required = details.get('required', 0)
            
            # åŸºç¡€åˆ†ï¼šæœ‰è¯¥ç±»åˆ«å¼•ç”¨å³å¾—åˆ†
            if count > 0:
                score += weight
                
                # å¥–åŠ±åˆ†ï¼šè¶…è¿‡æœ€ä½è¦æ±‚é¢å¤–åŠ åˆ†
                if count > required:
                    score += weight * 0.2
        
        return min(round(score, 2), 1.0)
    
    def _check_validation(
        self,
        citations: List[Dict],
        category_details: Dict[str, Dict],
        diversity_score: float
    ) -> Dict[str, Any]:
        """æ£€æŸ¥æ˜¯å¦é€šè¿‡éªŒè¯"""
        total_citations = len(citations)
        categories_covered = sum(1 for d in category_details.values() if d['count'] > 0)
        
        # æ£€æŸ¥å„é¡¹æ¡ä»¶
        checks = {
            'total_citations_ok': self.config.min_total_citations <= total_citations <= self.config.max_total_citations,
            'categories_ok': categories_covered >= self.config.min_categories,
            'diversity_ok': diversity_score >= self.config.min_diversity_score,
            'required_categories_ok': all(
                details['count'] >= details['required']
                for details in category_details.values()
                if details.get('is_required', False)
            )
        }
        
        # ä¸¥æ ¼æ¨¡å¼ä¸‹æ‰€æœ‰æœ€ä½è¦æ±‚å¿…é¡»æ»¡è¶³
        if self.config.strict_mode:
            checks['all_minimums_ok'] = all(
                details['count'] >= details['required']
                for details in category_details.values()
            )
        else:
            checks['all_minimums_ok'] = True
        
        overall_status = 'pass' if all(checks.values()) else 'fail'
        
        return {
            'overall_status': overall_status,
            'diversity_score': diversity_score,
            'categories_covered': categories_covered,
            'total_citations': total_citations,
            'checks': checks
        }
    
    def _generate_recommendations(
        self,
        citations: List[Dict],
        category_details: Dict[str, Dict],
        diversity_score: float
    ) -> Tuple[List[Dict], List[str]]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®å’Œè­¦å‘Š"""
        recommendations = []
        warnings = []
        
        total_citations = len(citations)
        categories_covered = sum(1 for d in category_details.values() if d['count'] > 0)
        
        # æ£€æŸ¥æ€»å¼•ç”¨æ•°
        if total_citations < self.config.min_total_citations:
            recommendations.append({
                'priority': 'medium',
                'category': None,
                'message': f"å½“å‰æ€»å¼•ç”¨æ•°ä¸º{total_citations}ï¼Œå»ºè®®å¢åŠ åˆ°{self.config.min_total_citations}-{self.config.max_total_citations}ç¯‡ã€‚",
                'search_suggestions': ["ä½¿ç”¨ai-deep-search-guideè¿›è¡Œæ›´å¤šæœç´¢"]
            })
        elif total_citations > self.config.max_total_citations:
            warnings.append(f"å¼•ç”¨æ•°é‡({total_citations})è¶…è¿‡å»ºè®®ä¸Šé™({self.config.max_total_citations})ï¼Œè€ƒè™‘ç²¾ç®€")
        
        # æ£€æŸ¥å„ç±»åˆ«
        for category, details in category_details.items():
            if details['status'] == 'fail':
                priority = 'high' if details.get('is_required', False) else 'medium'
                category_name = category.replace('_', ' ').title()
                
                recommendations.append({
                    'priority': priority,
                    'category': category,
                    'message': f"éœ€è¦è‡³å°‘{details['required']}ä¸ª{category_name}å¼•ç”¨ï¼Œå½“å‰åªæœ‰{details['count']}ä¸ªã€‚",
                    'search_suggestions': self.SEARCH_SUGGESTIONS.get(category, [])
                })
        
        # æ£€æŸ¥å¤šæ ·æ€§è¯„åˆ†
        if diversity_score < self.config.min_diversity_score:
            warnings.append(
                f"å¤šæ ·æ€§è¯„åˆ†({diversity_score})ä½äºæœ€ä½è¦æ±‚({self.config.min_diversity_score})"
            )
        
        # æ£€æŸ¥ç±»åˆ«è¦†ç›–
        if categories_covered < self.config.min_categories:
            warnings.append(
                f"ä»…è¦†ç›–{categories_covered}ä¸ªç±»åˆ«ï¼Œéœ€è¦è‡³å°‘{self.config.min_categories}ä¸ªç±»åˆ«"
            )
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºå»ºè®®
        priority_order = {'high': 0, 'medium': 1, 'low': 2}
        recommendations.sort(key=lambda x: priority_order.get(x['priority'], 99))
        
        return recommendations, warnings
    
    def get_improvement_plan(self, validation_result: Dict) -> str:
        """
        ç”Ÿæˆæ”¹è¿›è®¡åˆ’çš„æ–‡æœ¬æè¿°
        
        Args:
            validation_result: validate()æ–¹æ³•çš„è¾“å‡º
            
        Returns:
            æ”¹è¿›è®¡åˆ’æ–‡æœ¬
        """
        if validation_result['validation_result']['overall_status'] == 'pass':
            return "å¼•ç”¨å¤šæ ·æ€§éªŒè¯é€šè¿‡ï¼Œæ— éœ€æ”¹è¿›ã€‚"
        
        lines = ["## å¼•ç”¨å¤šæ ·æ€§æ”¹è¿›è®¡åˆ’\n"]
        
        # æ·»åŠ å½“å‰çŠ¶æ€
        result = validation_result['validation_result']
        lines.append(f"å½“å‰çŠ¶æ€: å¤šæ ·æ€§è¯„åˆ† {result['diversity_score']}, "
                    f"è¦†ç›– {result['categories_covered']} ä¸ªç±»åˆ«, "
                    f"å…± {result['total_citations']} ä¸ªå¼•ç”¨\n")
        
        # æ·»åŠ è­¦å‘Š
        if validation_result['warnings']:
            lines.append("### è­¦å‘Š")
            for warning in validation_result['warnings']:
                lines.append(f"- {warning}")
            lines.append("")
        
        # æ·»åŠ å»ºè®®
        if validation_result['recommendations']:
            lines.append("### æ”¹è¿›æ­¥éª¤")
            for i, rec in enumerate(validation_result['recommendations'], 1):
                priority_emoji = "ğŸ”´" if rec['priority'] == 'high' else "ğŸŸ¡"
                lines.append(f"\n{i}. {priority_emoji} {rec['message']}")
                
                if rec.get('search_suggestions'):
                    lines.append("   æœç´¢å»ºè®®:")
                    for suggestion in rec['search_suggestions']:
                        lines.append(f"   - {suggestion}")
        
        return '\n'.join(lines)


def validate_citations_diversity(
    citations: List[Dict[str, Any]],
    config_path: Optional[str] = None
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šéªŒè¯å¼•ç”¨å¤šæ ·æ€§
    
    Args:
        citations: å¼•ç”¨åˆ—è¡¨
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        éªŒè¯ç»“æœ
    """
    validator = CitationDiversityValidator(config_path=config_path)
    return validator.validate(citations)


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•å¼•ç”¨åˆ—è¡¨
    test_citations = [
        {'bibtex_key': 'smith2024optimization', 'category': 'academic'},
        {'bibtex_key': 'jones2023model', 'category': 'academic'},
        {'bibtex_key': 'chen2024analysis', 'category': 'academic'},
        {'bibtex_key': 'worldbank2024report', 'category': 'government'},
        {'bibtex_key': 'un2024data', 'category': 'data'},
        {'bibtex_key': 'mcm2024problema', 'category': 'problem'},
    ]
    
    validator = CitationDiversityValidator()
    result = validator.validate(test_citations)
    
    print("Validation Result:")
    print(f"Status: {result['validation_result']['overall_status']}")
    print(f"Diversity Score: {result['validation_result']['diversity_score']}")
    print(f"Categories Covered: {result['validation_result']['categories_covered']}")
    
    print("\nCategory Details:")
    for category, details in result['category_details'].items():
        print(f"  {category}: {details['count']}/{details['required']} ({details['status']})")
    
    if result['recommendations']:
        print("\nRecommendations:")
        for rec in result['recommendations']:
            print(f"  [{rec['priority']}] {rec['message']}")
    
    if result['warnings']:
        print("\nWarnings:")
        for warning in result['warnings']:
            print(f"  - {warning}")
    
    # æ‰“å°æ”¹è¿›è®¡åˆ’
    print("\n" + "="*50)
    print(validator.get_improvement_plan(result))
